Phabricator: [T370378](https://phabricator.wikimedia.org/T370378)

Status: Accepted

Date: September 20, 2024

# Problem statement

How should usage of `Data:` pages for chart definitions and tabular data be tracked, with support across the Wikimedia farm for invalidating cached pages on update?

# Decision outcome

After some discussion we decided not to make a more general multiple-type tracking solution, but to make one specific to `JsonConfig`-backed page consumption, of which Chart is the primary and initial consumer.

Most of this work will live in `JsonConfig`, and will be documented there as well.

Local (same-wiki) data usages will be tracked via `templatelinks` as though they were transclusions; this provides local dependency tracking through MediaWiki's existing systems and requires no extra per-wiki setup.

Remote data usages will be tracked in a set of shared database tables, which can live in a separate database server such as `x1` in production without being joined against any of the other MediaWiki tables. These will be created once globally, and do not require any manual per-wiki setup or maintenance.

This allows MediaWiki on Commons to queue a cleanup job after updating or deleting any `Data:` page and fire off a cache purge, allowing the page to be regenerated with fresh data.

Proposed database schema:

```lang=sql
-- This has the same schema as the linktarget table, but since we intend for globaljsonlinks to be in x1, we can't join against linktarget
CREATE TABLE globaljsonlinks_target (
    gjlt_id BIGINT UNSIGNED AUTO_INCREMENT NOT NULL,
    gjlt_namespace INT NOT NULL,
    gjlt_title VARBINARY(255) NOT NULL,
    UNIQUE INDEX gjlt_namespace_title (gjlt_namespace, gjlt_title),
    PRIMARY KEY (gjlt_id)
);

CREATE TABLE globaljsonlinks_namespace (
    gjln_id UNSIGNED AUTO_INCREMENT NOT NULL,
    gjln_wiki VARBINARY(32) NOT NULL,
    gjln_namespace VARBINARY(255) NOT NULL, /* remote so using text */
    UNIQUE INDEX gjln_wiki_namespace (gjln_wiki, gjln_namespace),
    PRIMARY KEY (gjln_id)
);

CREATE TABLE globaljsonlinks (
    gjl_namespace UNSIGNED NOT NULL, /* refers to globaljsonlinks_namespace.gjln_id */
    gjl_title VARBINARY(255) NOT NULL,
    gjl_target BIGINT UNSIGNED NOT NULL, /* refers to globaljsonlinks_target.gjlt_id */
    INDEX gjl_target_namespace_title (gjl_target, gjl_namespace, gjl_title),
    PRIMARY KEY (gjl_namespace, gjl_title, gjl_target)
);
```

The actual change propagation mechanism is proposed as:

* On update, Commons job purges any local pages using the `Data:` page
  * Any remote site with usages gets a single API hit with the updated `Data:` page reference
  * this API method queues a local-wiki job
    * local-wiki job checks the same table, and purges any local pages in turn

# Decision drivers

* Adding new tables is extra trouble for production. A single shared table is cleaner, and use of existing tables where they are suitable is good.
* While we have several distinct tracking systems and were tempted to consider merging them into one big one, they are distinct for a number of good reasons as they are often _slightly different_ in schema details, usage patterns, size concerns, etc. Making a new system for this specific usage avoids having to store a 'type' parameter or handle heavier levels of traffic of other kinds of data. We don't distinguish between different types of `Data:` pages here or different types of consumption, but are aiming at simply tracking consumption and propagating invalidations.
* Using a set of tables on a separate shared database allows for flexibility of DBA details, and makes it easy to query the same data from Commons and from the other wikis. However it does mean we can't reuse common "target" tables for other link tables; this is not expected to be a huge driver of space compared to other stuff here.
* `globaljsonlinks_target` allows conserving space when the same definitions of data sets are reused many times, as expected. There is a possibility of harmlessly leaking old target records if we don't actively prune them, taking up space.
* `globaljsonlinks_namespace` combines the wiki id and remote namespace name (as text, since we may not be able to deduce remote namespace inidices easily)
* `globaljsonlinks` matches up the smaller wiki/ns pair IDs with the `Data:` target page IDs from the other two tables. It should be quite compact, and makes it relatively easy to get a list of remote wikis to taget.

# Related questions for later

* Will we also track usage from the Lua tabular data loader and other such bits in `JsonConfig`?
